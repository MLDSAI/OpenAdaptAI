"""This script executes the InstructBLIP model within a modal container and
asks the questions from openadapt/vision/questions.txt about the images in
openadapt/vision/images.

To run this script, make sure you have created a modal token by
running the following:

    $ modal token new

Usage:

    $ modal run openadapt/vision/instructblip.py

"""

from modal import Image, Stub, method
from PIL import Image as PILImage

BASE_MODEL = "Salesforce/instructblip-vicuna-13b"
IMAGES_PATH = "openadapt/vision/images"
QUESTIONS_PATH = "openadapt/vision/questions.txt"

TIMEOUT = 18000
NUM_BEAMS = 5
MAX_LENGTH = (256,)
MIN_LENGTH = (1,)
TOP_P = (0.9,)
REPETITION_PENALTY = (1.5,)
LENGTH_PENALTY = (1.0,)
TEMPERATURE = (1,)


def download_models() -> None:
    """This function downloads the necessary InstructBlip models from Hugging Face's
    Transformers library.
    """
    from transformers import InstructBlipForConditionalGeneration, InstructBlipProcessor

    InstructBlipProcessor.from_pretrained(BASE_MODEL)
    InstructBlipForConditionalGeneration.from_pretrained(BASE_MODEL)


image = (
    Image.debian_slim(python_version="3.10")
    .apt_install("git")
    .pip_install(
        "accelerate~=0.20.3",
        "transformers @git+https://github.com/huggingface/transformers",
        "torch",
        "Pillow",
    )
    .run_function(download_models)
)

stub = Stub(name="instructblip_vicuna_13b", image=image)


@stub.cls(gpu="A100", timeout=TIMEOUT)
class InstructBlipModel:
    """This class facilitates interactions with the InstructBlip model.
    Sample usage where pil_image is an open PIL Image and question is a string:
    >>> model = InstructBlipModel()
    >>> model.generate.call(pil_image, question)
    """

    def __enter__(self) -> None:
        """
        Automatically initialize the InstructBlip model and processor upon initializing
        the InstructBlipModel class.
        """

        from transformers import (
            InstructBlipForConditionalGeneration,
            InstructBlipProcessor,
        )
        import torch

        self.processor = InstructBlipProcessor.from_pretrained(BASE_MODEL)

        self.model = InstructBlipForConditionalGeneration.from_pretrained(
            BASE_MODEL, torch_dtype=torch.float16, device_map="auto"
        )
        self.device = "cuda"

    @method()
    def generate(
        self,
        image: PILImage,
        question: str,
    ) -> str:
        """Generate a completion for the given question about the given image.
        Use .call to call this function in the modal container.

        Args:
            image (PILImage): an image to pass to the model
            question (str): a question about the image

        Returns:
            str: the completion generated by the model
        """

        import torch

        inputs = self.processor(images=image, text=question, return_tensors="pt").to(
            self.device, torch.float16
        )
        out = self.model.generate(
            **inputs,
            do_sample=False,
            num_beams=NUM_BEAMS,
            max_length=MAX_LENGTH,
            min_length=MIN_LENGTH,
            top_p=TOP_P,
            repetition_penalty=REPETITION_PENALTY,
            length_penalty=LENGTH_PENALTY,
            temperature=TEMPERATURE,
        )
        return self.processor.batch_decode(out, skip_special_tokens=True)[0].strip()


@stub.local_entrypoint()
def main() -> None:
    """Entrypoint for the modal container."""

    import os

    from PIL import Image

    model = InstructBlipModel()

    with open(QUESTIONS_PATH, "r") as file:
        lines = file.readlines()
        questions = [line.strip() for line in lines]

    images = os.listdir(IMAGES_PATH)
    for image in images:
        print(f"Current image: {image}")
        image_path = os.path.join(IMAGES_PATH, image)
        pil_image = Image.open(image_path).convert("RGB")

        for question in questions:
            print(f"Question: {question}")
            response = model.generate.call(
                pil_image,
                question,
            )
            print(response)
